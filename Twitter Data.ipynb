{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in /home/narges/anaconda3/lib/python3.7/site-packages (4.10.1)\n",
      "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in /home/narges/anaconda3/lib/python3.7/site-packages (from tweepy) (1.3.1)\n",
      "Requirement already satisfied: oauthlib<4,>=3.2.0 in /home/narges/anaconda3/lib/python3.7/site-packages (from tweepy) (3.2.1)\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in /home/narges/anaconda3/lib/python3.7/site-packages (from tweepy) (2.28.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/narges/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.27.0->tweepy) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/narges/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.27.0->tweepy) (1.25.8)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/narges/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.27.0->tweepy) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/narges/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.27.0->tweepy) (2019.11.28)\n"
     ]
    }
   ],
   "source": [
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONSUMER_KEY = os.environ['CONSUMER_KEY']\n",
    "CONSUMER_SECRET = os.environ['CONSUMER_SECRET']\n",
    "ACCESS_TOKEN = os.environ['ACCESS_TOKEN']\n",
    "ACCESS_TOKEN_SECRET = os.environ['ACCESS_TOKEN_SECRET']\n",
    "BEARER_TOKEN = os.environ['BEARER_TOKEN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "dump_path = Path('./data/twitter_data/')\n",
    "if not dump_path.exists():\n",
    "    dump_path.mkdir()\n",
    "\n",
    "for page in tqdm(tweepy.Cursor(\n",
    "    api.search_tweets,\n",
    "    tweet_mode='extended',\n",
    "    q = \"#machine_learning\",\n",
    "    count = 10,\n",
    "    # lang=\"en\",\n",
    ").pages(2)):\n",
    "    for tweet in page:\n",
    "        json_data = tweet._json\n",
    "        with open(dump_path / f'{json_data[\"id\"]}.json', 'w') as f:\n",
    "            json.dump(json_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Dumped Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path('./data/twitter_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(file_path):\n",
    "    with open(file_path) as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:00, 2630.98it/s]\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for file_path in tqdm(DATA_DIR.iterdir()):\n",
    "    if file_path.is_dir():\n",
    "        continue\n",
    "    d = read_json(file_path)\n",
    "    \n",
    "    rows.append(dict(\n",
    "        name = d['user']['name'],\n",
    "        followers = d['user']['followers_count'],\n",
    "        following = d['user']['friends_count'],\n",
    "        follower_following_ratio =  d['user']['followers_count'] / (d['user']['friends_count'] + 1),\n",
    "        text = d.get('full_text') or d.get('text'),\n",
    "        hashtags = list(map(lambda item: item['text'], d['entities']['hashtags'])),\n",
    "        likes = d['favorite_count'],\n",
    "        retweets = d['retweet_count'],\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.min_rows', 20)\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>followers</th>\n",
       "      <th>following</th>\n",
       "      <th>follower_following_ratio</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lucifer AI</td>\n",
       "      <td>37</td>\n",
       "      <td>194</td>\n",
       "      <td>0.189744</td>\n",
       "      <td>#30DaysOfCodechallenge\\nDay22\\nNot done much today. Just started eda for new project\\n#30Daysofcode challenge to train my model with ML algorithms intuitions. \\nSo much to data to train. .\\n#machi...</td>\n",
       "      <td>[30DaysOfCodechallenge, 30Daysofcode, machine_learning, DataScience, bot_training, Python]</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coding Buddy</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>RT @lucifer_twtt: #30DaysOfCodechallenge\\nDay22\\nNot done much today. Just started eda for new project\\n#30Daysofcode challenge to train my mo‚Ä¶</td>\n",
       "      <td>[30DaysOfCodechallenge, 30Daysofcode]</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AI Bot by uCloudify.com</td>\n",
       "      <td>991</td>\n",
       "      <td>0</td>\n",
       "      <td>991.000000</td>\n",
       "      <td>RT @lucifer_twtt: #30DaysOfCodechallenge\\nDay22\\nNot done much today. Just started eda for new project\\n#30Daysofcode challenge to train my mo‚Ä¶</td>\n",
       "      <td>[30DaysOfCodechallenge, 30Daysofcode]</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#30DaysOfCode</td>\n",
       "      <td>2318</td>\n",
       "      <td>1</td>\n",
       "      <td>1159.000000</td>\n",
       "      <td>RT @lucifer_twtt: #30DaysOfCodechallenge\\nDay22\\nNot done much today. Just started eda for new project\\n#30Daysofcode challenge to train my mo‚Ä¶</td>\n",
       "      <td>[30DaysOfCodechallenge, 30Daysofcode]</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PyBot</td>\n",
       "      <td>902</td>\n",
       "      <td>1</td>\n",
       "      <td>451.000000</td>\n",
       "      <td>RT @lucifer_twtt: #30DaysOfCodechallenge\\nDay22\\nNot done much today. Just started eda for new project\\n#30Daysofcode challenge to train my mo‚Ä¶</td>\n",
       "      <td>[30DaysOfCodechallenge, 30Daysofcode]</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mr Data Scientist</td>\n",
       "      <td>10965</td>\n",
       "      <td>270</td>\n",
       "      <td>40.461255</td>\n",
       "      <td>RT @lucifer_twtt: #30DaysOfCodechallenge\\nDay22\\nNot done much today. Just started eda for new project\\n#30Daysofcode challenge to train my mo‚Ä¶</td>\n",
       "      <td>[30DaysOfCodechallenge, 30Daysofcode]</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SUPER WRITERS</td>\n",
       "      <td>178</td>\n",
       "      <td>441</td>\n",
       "      <td>0.402715</td>\n",
       "      <td>We can complete your;\\n#Homework \\n#Machine_Learning \\n#Data_Science\\n#Assignments\\n#Stats \\n#Fall_classes\\n#Finals\\n#Pearson\\n#Python\\n#R_programming_Language\\n#Stata\\n#Spss\\n#JavaScript\\nGet Qui...</td>\n",
       "      <td>[Homework, Machine_Learning, Data_Science, Assignments, Stats, Fall_classes, Finals, Pearson, Python, R_programming_Language, Stata, Spss, JavaScript, We_deliver]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PyBot</td>\n",
       "      <td>902</td>\n",
       "      <td>1</td>\n",
       "      <td>451.000000</td>\n",
       "      <td>RT @superwriterz: We can complete your;\\n#Homework \\n#Machine_Learning \\n#Data_Science\\n#Assignments\\n#Stats \\n#Fall_classes\\n#Finals\\n#Pearson\\n#Py‚Ä¶</td>\n",
       "      <td>[Homework, Machine_Learning, Data_Science, Assignments, Stats, Fall_classes, Finals, Pearson]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Xeron Bot</td>\n",
       "      <td>2309</td>\n",
       "      <td>1</td>\n",
       "      <td>1154.500000</td>\n",
       "      <td>RT @superwriterz: We can complete your;\\n#Homework \\n#Machine_Learning \\n#Data_Science\\n#Assignments\\n#Stats \\n#Fall_classes\\n#Finals\\n#Pearson\\n#Py‚Ä¶</td>\n",
       "      <td>[Homework, Machine_Learning, Data_Science, Assignments, Stats, Fall_classes, Finals, Pearson]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>//InsertUsefulComment</td>\n",
       "      <td>45</td>\n",
       "      <td>212</td>\n",
       "      <td>0.211268</td>\n",
       "      <td>RT @SmitterHane: Just use it\\n#DataScience #CodeNewbie #code #100DaysOfCode #100Devs #python #machine_learning #ArtificialIntelligence #joke‚Ä¶</td>\n",
       "      <td>[DataScience, CodeNewbie, code, 100DaysOfCode, 100Devs, python, machine_learning, ArtificialIntelligence]</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>STATS HOMEWORK HELPERS</td>\n",
       "      <td>36</td>\n",
       "      <td>210</td>\n",
       "      <td>0.170616</td>\n",
       "      <td>We can complete your;\\n#Homework \\n#Machine_Learning \\n#Data_Science\\n#Assignments\\n#Stats \\n#Fall_classes\\n#Pearsons\\n#Stats_Class\\n#Finals\\n#Python\\n#R_programming_Language\\n#Stata\\n#Spss\\n#Java...</td>\n",
       "      <td>[Homework, Machine_Learning, Data_Science, Assignments, Stats, Fall_classes, Pearsons, Stats_Class, Finals, Python, R_programming_Language, Stata, Spss, JavaScript, We_deliver]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Akintayo</td>\n",
       "      <td>68</td>\n",
       "      <td>36</td>\n",
       "      <td>1.837838</td>\n",
       "      <td>RT @stats_helpers: We can complete your;\\n#Homework \\n#Machine_Learning \\n#Data_Science\\n#Assignments\\n#Stats \\n#Fall_classes\\n#Pearsons\\n#Stats_Cl‚Ä¶</td>\n",
       "      <td>[Homework, Machine_Learning, Data_Science, Assignments, Stats, Fall_classes, Pearsons]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Read Tech Here</td>\n",
       "      <td>815</td>\n",
       "      <td>310</td>\n",
       "      <td>2.620579</td>\n",
       "      <td>RT @stats_helpers: We can complete your;\\n#Homework \\n#Machine_Learning \\n#Data_Science\\n#Assignments\\n#Stats \\n#Fall_classes\\n#Pearsons\\n#Stats_Cl‚Ä¶</td>\n",
       "      <td>[Homework, Machine_Learning, Data_Science, Assignments, Stats, Fall_classes, Pearsons]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Unemployed Professor</td>\n",
       "      <td>29</td>\n",
       "      <td>176</td>\n",
       "      <td>0.163842</td>\n",
       "      <td>Let's handle your;\\n#Homework \\n#Machine_Learning \\n#Data_Science\\n#Assignments\\n#Stats \\n#Fall_classes\\n#Pearsons\\n#Stats_Class\\n#Finals\\n#Python\\n#R_programming_Language\\n#Stata\\n#Spss\\n#JavaScr...</td>\n",
       "      <td>[Homework, Machine_Learning, Data_Science, Assignments, Stats, Fall_classes, Pearsons, Stats_Class, Finals, Python, R_programming_Language, Stata, Spss, JavaScript, We_deliver]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Utibe-Abasi Jacob Udoh</td>\n",
       "      <td>423</td>\n",
       "      <td>888</td>\n",
       "      <td>0.475816</td>\n",
       "      <td>RT @Tutor_Nolan: Let's handle your;\\n#Homework \\n#Machine_Learning \\n#Data_Science\\n#Assignments\\n#Stats \\n#Fall_classes\\n#Pearsons\\n#Stats_Class\\n#‚Ä¶</td>\n",
       "      <td>[Homework, Machine_Learning, Data_Science, Assignments, Stats, Fall_classes, Pearsons, Stats_Class]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Xeron Bot</td>\n",
       "      <td>2309</td>\n",
       "      <td>1</td>\n",
       "      <td>1154.500000</td>\n",
       "      <td>RT @Tutor_Nolan: Let's handle your;\\n#Homework \\n#Machine_Learning \\n#Data_Science\\n#Assignments\\n#Stats \\n#Fall_classes\\n#Pearsons\\n#Stats_Class\\n#‚Ä¶</td>\n",
       "      <td>[Homework, Machine_Learning, Data_Science, Assignments, Stats, Fall_classes, Pearsons, Stats_Class]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ÿßŸÖ ŸÖÿ≠ŸÖÿØ</td>\n",
       "      <td>35</td>\n",
       "      <td>87</td>\n",
       "      <td>0.397727</td>\n",
       "      <td>RT @AshwagAlbukhari: üìçüìçüìç\\nhappening now as part of ‚Äú#Ai for #precision_medicine‚Äù student program @UniofOxford \\n\\n‚ÄúIntroduction to coding in #‚Ä¶</td>\n",
       "      <td>[Ai, precision_medicine]</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Fermentation</td>\n",
       "      <td>359</td>\n",
       "      <td>539</td>\n",
       "      <td>0.664815</td>\n",
       "      <td>An article entitled \"Predicting #Alcohol Concentration during #Beer_Fermentation Using Ultrasonic Measurements and #Machine_Learning\" from Dr. Nicholas Watson et al.\\n\\nView full text at:\\nhttps:/...</td>\n",
       "      <td>[Alcohol, Beer_Fermentation, Machine_Learning]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Lonewollffü•ë</td>\n",
       "      <td>539</td>\n",
       "      <td>3479</td>\n",
       "      <td>0.154885</td>\n",
       "      <td>@datawithsuman @SaveToNotion  #machine_learning</td>\n",
       "      <td>[machine_learning]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ŸàÿßŸäÿ™ ÿ¨ŸàŸÑÿØ | ÿÆÿØŸÖÿßÿ™ ÿ®ÿ±ŸÖÿ¨Ÿäÿ©</td>\n",
       "      <td>261</td>\n",
       "      <td>570</td>\n",
       "      <td>0.457093</td>\n",
       "      <td>üîóŸÜŸÇÿØŸÖ ÿßŸÑŸÖÿ≥ÿßÿπÿØÿ© ŸÑÿ∑ŸÑÿ®ÿ© #ÿßŸÑÿØÿ±ÿßÿ≥ÿßÿ™_ÿßŸÑÿπŸÑŸäÿß ŸÅŸä ŸÖÿ¨ÿßŸÑ #ÿßŸÑŸáŸÜÿØÿ≥ÿ© ŸÅŸä ÿßÿπÿØÿßÿØ #ÿßŸÑŸÖÿ¥ÿßÿ±Ÿäÿπ Ÿà #ÿßŸÑÿ®ÿ≠Ÿàÿ´ ŸÅŸä ÿßŸÑŸÖÿ¨ÿßŸÑÿßÿ™ ÿßŸÑÿ™ÿßŸÑŸäÿ©:\\n#Machine_Learning\\n#ArtificialIntelligence\\n#DataMining\\n#DeepLearning\\n*#CyberSecurity\\nüîó...</td>\n",
       "      <td>[ÿßŸÑÿØÿ±ÿßÿ≥ÿßÿ™_ÿßŸÑÿπŸÑŸäÿß, ÿßŸÑŸáŸÜÿØÿ≥ÿ©, ÿßŸÑŸÖÿ¥ÿßÿ±Ÿäÿπ, ÿßŸÑÿ®ÿ≠Ÿàÿ´, Machine_Learning, ArtificialIntelligence, DataMining, DeepLearning, CyberSecurity, ŸàÿßŸäÿ™_ÿ¨ŸàŸÑÿØ, ÿ¨ÿßŸÖÿπÿ©_ÿßŸÑÿ®ÿπÿ´, ÿ¨ÿßŸÖÿπÿ©_ÿßŸÑÿ£ŸÖŸäÿ±ÿ©_ŸÜŸàÿ±ÿ©, ÿ¨ÿØÿ©]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name  followers  following  follower_following_ratio  \\\n",
       "0                 Lucifer AI         37        194                  0.189744   \n",
       "1               Coding Buddy          9          2                  3.000000   \n",
       "2    AI Bot by uCloudify.com        991          0                991.000000   \n",
       "3              #30DaysOfCode       2318          1               1159.000000   \n",
       "4                      PyBot        902          1                451.000000   \n",
       "5          Mr Data Scientist      10965        270                 40.461255   \n",
       "6              SUPER WRITERS        178        441                  0.402715   \n",
       "7                      PyBot        902          1                451.000000   \n",
       "8                  Xeron Bot       2309          1               1154.500000   \n",
       "9      //InsertUsefulComment         45        212                  0.211268   \n",
       "10    STATS HOMEWORK HELPERS         36        210                  0.170616   \n",
       "11                  Akintayo         68         36                  1.837838   \n",
       "12            Read Tech Here        815        310                  2.620579   \n",
       "13      Unemployed Professor         29        176                  0.163842   \n",
       "14    Utibe-Abasi Jacob Udoh        423        888                  0.475816   \n",
       "15                 Xeron Bot       2309          1               1154.500000   \n",
       "16                   ÿßŸÖ ŸÖÿ≠ŸÖÿØ         35         87                  0.397727   \n",
       "17              Fermentation        359        539                  0.664815   \n",
       "18               Lonewollffü•ë        539       3479                  0.154885   \n",
       "19  ŸàÿßŸäÿ™ ÿ¨ŸàŸÑÿØ | ÿÆÿØŸÖÿßÿ™ ÿ®ÿ±ŸÖÿ¨Ÿäÿ©        261        570                  0.457093   \n",
       "\n",
       "                                                                                                                                                                                                       text  \\\n",
       "0   #30DaysOfCodechallenge\\nDay22\\nNot done much today. Just started eda for new project\\n#30Daysofcode challenge to train my model with ML algorithms intuitions. \\nSo much to data to train. .\\n#machi...   \n",
       "1                                                           RT @lucifer_twtt: #30DaysOfCodechallenge\\nDay22\\nNot done much today. Just started eda for new project\\n#30Daysofcode challenge to train my mo‚Ä¶   \n",
       "2                                                           RT @lucifer_twtt: #30DaysOfCodechallenge\\nDay22\\nNot done much today. Just started eda for new project\\n#30Daysofcode challenge to train my mo‚Ä¶   \n",
       "3                                                           RT @lucifer_twtt: #30DaysOfCodechallenge\\nDay22\\nNot done much today. Just started eda for new project\\n#30Daysofcode challenge to train my mo‚Ä¶   \n",
       "4                                                           RT @lucifer_twtt: #30DaysOfCodechallenge\\nDay22\\nNot done much today. Just started eda for new project\\n#30Daysofcode challenge to train my mo‚Ä¶   \n",
       "5                                                           RT @lucifer_twtt: #30DaysOfCodechallenge\\nDay22\\nNot done much today. Just started eda for new project\\n#30Daysofcode challenge to train my mo‚Ä¶   \n",
       "6   We can complete your;\\n#Homework \\n#Machine_Learning \\n#Data_Science\\n#Assignments\\n#Stats \\n#Fall_classes\\n#Finals\\n#Pearson\\n#Python\\n#R_programming_Language\\n#Stata\\n#Spss\\n#JavaScript\\nGet Qui...   \n",
       "7                                                     RT @superwriterz: We can complete your;\\n#Homework \\n#Machine_Learning \\n#Data_Science\\n#Assignments\\n#Stats \\n#Fall_classes\\n#Finals\\n#Pearson\\n#Py‚Ä¶   \n",
       "8                                                     RT @superwriterz: We can complete your;\\n#Homework \\n#Machine_Learning \\n#Data_Science\\n#Assignments\\n#Stats \\n#Fall_classes\\n#Finals\\n#Pearson\\n#Py‚Ä¶   \n",
       "9                                                             RT @SmitterHane: Just use it\\n#DataScience #CodeNewbie #code #100DaysOfCode #100Devs #python #machine_learning #ArtificialIntelligence #joke‚Ä¶   \n",
       "10  We can complete your;\\n#Homework \\n#Machine_Learning \\n#Data_Science\\n#Assignments\\n#Stats \\n#Fall_classes\\n#Pearsons\\n#Stats_Class\\n#Finals\\n#Python\\n#R_programming_Language\\n#Stata\\n#Spss\\n#Java...   \n",
       "11                                                     RT @stats_helpers: We can complete your;\\n#Homework \\n#Machine_Learning \\n#Data_Science\\n#Assignments\\n#Stats \\n#Fall_classes\\n#Pearsons\\n#Stats_Cl‚Ä¶   \n",
       "12                                                     RT @stats_helpers: We can complete your;\\n#Homework \\n#Machine_Learning \\n#Data_Science\\n#Assignments\\n#Stats \\n#Fall_classes\\n#Pearsons\\n#Stats_Cl‚Ä¶   \n",
       "13  Let's handle your;\\n#Homework \\n#Machine_Learning \\n#Data_Science\\n#Assignments\\n#Stats \\n#Fall_classes\\n#Pearsons\\n#Stats_Class\\n#Finals\\n#Python\\n#R_programming_Language\\n#Stata\\n#Spss\\n#JavaScr...   \n",
       "14                                                    RT @Tutor_Nolan: Let's handle your;\\n#Homework \\n#Machine_Learning \\n#Data_Science\\n#Assignments\\n#Stats \\n#Fall_classes\\n#Pearsons\\n#Stats_Class\\n#‚Ä¶   \n",
       "15                                                    RT @Tutor_Nolan: Let's handle your;\\n#Homework \\n#Machine_Learning \\n#Data_Science\\n#Assignments\\n#Stats \\n#Fall_classes\\n#Pearsons\\n#Stats_Class\\n#‚Ä¶   \n",
       "16                                                          RT @AshwagAlbukhari: üìçüìçüìç\\nhappening now as part of ‚Äú#Ai for #precision_medicine‚Äù student program @UniofOxford \\n\\n‚ÄúIntroduction to coding in #‚Ä¶   \n",
       "17  An article entitled \"Predicting #Alcohol Concentration during #Beer_Fermentation Using Ultrasonic Measurements and #Machine_Learning\" from Dr. Nicholas Watson et al.\\n\\nView full text at:\\nhttps:/...   \n",
       "18                                                                                                                                                          @datawithsuman @SaveToNotion  #machine_learning   \n",
       "19  üîóŸÜŸÇÿØŸÖ ÿßŸÑŸÖÿ≥ÿßÿπÿØÿ© ŸÑÿ∑ŸÑÿ®ÿ© #ÿßŸÑÿØÿ±ÿßÿ≥ÿßÿ™_ÿßŸÑÿπŸÑŸäÿß ŸÅŸä ŸÖÿ¨ÿßŸÑ #ÿßŸÑŸáŸÜÿØÿ≥ÿ© ŸÅŸä ÿßÿπÿØÿßÿØ #ÿßŸÑŸÖÿ¥ÿßÿ±Ÿäÿπ Ÿà #ÿßŸÑÿ®ÿ≠Ÿàÿ´ ŸÅŸä ÿßŸÑŸÖÿ¨ÿßŸÑÿßÿ™ ÿßŸÑÿ™ÿßŸÑŸäÿ©:\\n#Machine_Learning\\n#ArtificialIntelligence\\n#DataMining\\n#DeepLearning\\n*#CyberSecurity\\nüîó...   \n",
       "\n",
       "                                                                                                                                                                            hashtags  \\\n",
       "0                                                                                         [30DaysOfCodechallenge, 30Daysofcode, machine_learning, DataScience, bot_training, Python]   \n",
       "1                                                                                                                                              [30DaysOfCodechallenge, 30Daysofcode]   \n",
       "2                                                                                                                                              [30DaysOfCodechallenge, 30Daysofcode]   \n",
       "3                                                                                                                                              [30DaysOfCodechallenge, 30Daysofcode]   \n",
       "4                                                                                                                                              [30DaysOfCodechallenge, 30Daysofcode]   \n",
       "5                                                                                                                                              [30DaysOfCodechallenge, 30Daysofcode]   \n",
       "6                 [Homework, Machine_Learning, Data_Science, Assignments, Stats, Fall_classes, Finals, Pearson, Python, R_programming_Language, Stata, Spss, JavaScript, We_deliver]   \n",
       "7                                                                                      [Homework, Machine_Learning, Data_Science, Assignments, Stats, Fall_classes, Finals, Pearson]   \n",
       "8                                                                                      [Homework, Machine_Learning, Data_Science, Assignments, Stats, Fall_classes, Finals, Pearson]   \n",
       "9                                                                          [DataScience, CodeNewbie, code, 100DaysOfCode, 100Devs, python, machine_learning, ArtificialIntelligence]   \n",
       "10  [Homework, Machine_Learning, Data_Science, Assignments, Stats, Fall_classes, Pearsons, Stats_Class, Finals, Python, R_programming_Language, Stata, Spss, JavaScript, We_deliver]   \n",
       "11                                                                                            [Homework, Machine_Learning, Data_Science, Assignments, Stats, Fall_classes, Pearsons]   \n",
       "12                                                                                            [Homework, Machine_Learning, Data_Science, Assignments, Stats, Fall_classes, Pearsons]   \n",
       "13  [Homework, Machine_Learning, Data_Science, Assignments, Stats, Fall_classes, Pearsons, Stats_Class, Finals, Python, R_programming_Language, Stata, Spss, JavaScript, We_deliver]   \n",
       "14                                                                               [Homework, Machine_Learning, Data_Science, Assignments, Stats, Fall_classes, Pearsons, Stats_Class]   \n",
       "15                                                                               [Homework, Machine_Learning, Data_Science, Assignments, Stats, Fall_classes, Pearsons, Stats_Class]   \n",
       "16                                                                                                                                                          [Ai, precision_medicine]   \n",
       "17                                                                                                                                    [Alcohol, Beer_Fermentation, Machine_Learning]   \n",
       "18                                                                                                                                                                [machine_learning]   \n",
       "19  [ÿßŸÑÿØÿ±ÿßÿ≥ÿßÿ™_ÿßŸÑÿπŸÑŸäÿß, ÿßŸÑŸáŸÜÿØÿ≥ÿ©, ÿßŸÑŸÖÿ¥ÿßÿ±Ÿäÿπ, ÿßŸÑÿ®ÿ≠Ÿàÿ´, Machine_Learning, ArtificialIntelligence, DataMining, DeepLearning, CyberSecurity, ŸàÿßŸäÿ™_ÿ¨ŸàŸÑÿØ, ÿ¨ÿßŸÖÿπÿ©_ÿßŸÑÿ®ÿπÿ´, ÿ¨ÿßŸÖÿπÿ©_ÿßŸÑÿ£ŸÖŸäÿ±ÿ©_ŸÜŸàÿ±ÿ©, ÿ¨ÿØÿ©]   \n",
       "\n",
       "    likes  retweets  \n",
       "0       0         5  \n",
       "1       0         5  \n",
       "2       0         5  \n",
       "3       0         5  \n",
       "4       0         5  \n",
       "5       0         5  \n",
       "6       0         2  \n",
       "7       0         2  \n",
       "8       0         2  \n",
       "9       0        24  \n",
       "10      0         2  \n",
       "11      0         2  \n",
       "12      0         2  \n",
       "13      0         2  \n",
       "14      0         2  \n",
       "15      0         2  \n",
       "16      0        10  \n",
       "17      0         0  \n",
       "18      0         0  \n",
       "19      0         0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
